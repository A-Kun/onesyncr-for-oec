<h3>To achieve the basic requirements, we first have a crawler to crawl through data from two catalogues. It also generates a report and a data file. Then we have a function that creates a pull request on GitHub, and an email sending function that takes the pull request and the report to send to the user. All data should come with attributions and references, so we have another function to get those from other catalogues. Once the email is received, we have two more functions that lets the administrator choose to accept or reject the merge request on GitHub. We also plan to have an editor, which allows the client to edit the generated data file manually, if he would like, before merging into database. We will also implement a function that identifies the data about the same planet from different catalogues and generates two columns to compare and display the data to the client. We will add extra functionalities to the email sending part if we have time that allows users to change the time of the email being sent and also includes an error report when the program fails to connect the databases. Another function that is nice to have is a button in the email that allows the user to go back to the last version of git. 
Above is a brief description of our system design. Our project had a smooth transaction from deliverable 2 to deliverable 3. We put our user stories from deliverable 2 into our backlog and have an estimated project velocity of 4 user stories per sprint. We followed our plan and finished 3 user stories in this sprint. For the one user story that is not finished and some subtasks that do not work yet perfectly we are re-planning them into the next sprint.
</h3>
